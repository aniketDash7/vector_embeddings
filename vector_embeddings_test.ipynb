{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASTRA_DB_APPLICATION_TOKEN = 'AstraCS:SplgLOUegJESAHZtZJcMUzgc:ec505b848c9567b845d7f8a7925972681b8c1db7d49712ed944864d7f8b10cc9'\n",
    "ASTRA_DB_CLIENT_ID = 'c96e0498-325a-4c33-b7c2-9e8bc1c4e33a'\n",
    "ASTRA_DB_SECURE_BUNDLE_PATH = 'C:/Users/Aniket/Documents/Data Science/ML/assistant/secure-connect-vector-database.zip'\n",
    "ASTRA_DB_API_ENDPOINT = 'https://c96e0498-325a-4c33-b7c2-9e8bc1c4e33a-us-east1.apps.astra.datastax.com'\n",
    "ASTRA_DB_KEYSPACE = 'default_keyspace'\n",
    "OPENAI_API_KEY = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from langchain.vectorstores import AstraDB\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying the embedding model, database and collection to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embe = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "vstore = AstraDB(\n",
    "    embedding=embe,\n",
    "    collection_name=\"astra_vector_demo\",\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "    namespace=ASTRA_DB_KEYSPACE,    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the python dataset module we load small datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Playing around with the philosopher-quotes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example entry:\n",
      "{'author': 'aristotle', 'quote': 'At his best, man is the noblest of all animals; separated from law and justice he is the worst.', 'tags': 'ethics'}\n"
     ]
    }
   ],
   "source": [
    "philo_dataset = load_dataset(\"datastax/philosopher-quotes\")[\"train\"]\n",
    "print(\"An example entry:\")\n",
    "print(philo_dataset[19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing metadata and converting to langchain documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['author', 'quote', 'tags'],\n",
       "    num_rows: 450\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "philo_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing entries from a philosophy dataset, extracts metadata such as authors and tags, creates Document instances with this metadata, stores them in a list, and then inserts them into a database using a wrapper class or module called vstore, likely facilitating interactions with an AstraDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inserted 450 documents.\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "for entry in philo_dataset:\n",
    "    metadata = {\"author\": entry[\"author\"]}\n",
    "    if entry[\"tags\"]:\n",
    "        for tag in entry[\"tags\"].split(\";\"):\n",
    "            metadata[tag] = \"y\"\n",
    "    doc = Document(page_content=entry[\"quote\"], metadata=metadata)\n",
    "    docs.append(doc)\n",
    "#Computing embeddings for each document and store in the database.\n",
    "inserted_ids = vstore.add_documents(docs)\n",
    "print(f\"\\nInserted {len(inserted_ids)} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a batch of texts, along with their metadata and IDs, into the database using the vstore instance, facilitating efficient storage and retrieval of philosophical text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inserted 2 documents.\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"I think, therefore I am.\",\n",
    "    \"To the things themselves!\",\n",
    "]\n",
    "metadatas = [\n",
    "    {\"author\": \"descartes\", \"knowledge\": \"y\"},\n",
    "    {\"author\": \"husserl\", \"knowledge\": \"y\"},\n",
    "]\n",
    "ids = [\n",
    "    \"desc_01\",\n",
    "    \"huss_xy\",\n",
    "]\n",
    "inserted_ids_2 = vstore.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
    "print(f\"\\nInserted {len(inserted_ids_2)} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code will print out the content of the top 3 documents that are most similar to the input text, along with their associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Never discourage anyone who continually makes progress, no matter how slow... even if that someone is yourself! [{'author': 'plato', 'ethics': 'y', 'knowledge': 'y'}]\n",
      "* Never discourage anyone who continually makes progress, no matter how slow... even if that someone is yourself! [{'author': 'plato', 'ethics': 'y', 'knowledge': 'y'}]\n",
      "* Let unswerving integrity be your watchword. [{'author': 'spinoza', 'ethics': 'y'}]\n"
     ]
    }
   ],
   "source": [
    "results = vstore.similarity_search(\"Don't let doubt ruin your efforts\", k=3)\n",
    "for res in results:\n",
    "    print(f\"- {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.927852] Love well, be loved and do something of value. [{'author': 'aristotle', 'love': 'y', 'ethics': 'y'}]\n",
      "* [SIM=0.927852] Love well, be loved and do something of value. [{'author': 'aristotle', 'love': 'y', 'ethics': 'y'}]\n",
      "* [SIM=0.921863] Do the right thing because it is right. [{'author': 'kant', 'ethics': 'y'}]\n"
     ]
    }
   ],
   "source": [
    "results = vstore.similarity_search_with_score(\"Do what you love\", k=3)\n",
    "for res, score in results:\n",
    "    print(f\"- [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
